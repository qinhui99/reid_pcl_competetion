{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n20200830\\n这是一个start code,用来学习reid项目。\\n仅仅使用官方给的train数据进行训练，没有使用外部数据。\\n使用flip数据增强\\n使用densenet121网络训练和抽取特征。\\n保存最佳模型，在预测前加载\\n使用fp16进行训练。\\n没有re-ranking。\\nlb 0.357\\n\\n代码的基本框架来源于郑哲东大神的开源项目：https://github.com/layumi/Person_reID_baseline_pytorch\\n环境：pytorch 1.4\\n训练60个epoch\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "20200830\n",
    "这是一个start code,用来学习reid项目。\n",
    "仅仅使用官方给的train数据进行训练，没有使用外部数据。\n",
    "使用flip数据增强\n",
    "使用densenet121网络训练和抽取特征。\n",
    "保存最佳模型，在预测前加载\n",
    "使用fp16进行训练。\n",
    "没有re-ranking。\n",
    "lb 0.357\n",
    "\n",
    "代码的基本框架来源于郑哲东大神的开源项目：https://github.com/layumi/Person_reID_baseline_pytorch\n",
    "环境：pytorch 1.4\n",
    "训练60个epoch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00040591.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066284.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00025569.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00024054.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00028221.png</td>\n",
       "      <td>4664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72819</th>\n",
       "      <td>00024418.png</td>\n",
       "      <td>4332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72820</th>\n",
       "      <td>00029689.png</td>\n",
       "      <td>15371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72821</th>\n",
       "      <td>00026579.png</td>\n",
       "      <td>15371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72822</th>\n",
       "      <td>00017589.png</td>\n",
       "      <td>17149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72823</th>\n",
       "      <td>00043388.png</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             img_id  target\n",
       "0      00040591.png   15178\n",
       "1      00066284.png   15178\n",
       "2      00025569.png   15178\n",
       "3      00024054.png   15178\n",
       "4      00028221.png    4664\n",
       "...             ...     ...\n",
       "72819  00024418.png    4332\n",
       "72820  00029689.png   15371\n",
       "72821  00026579.png   15371\n",
       "72822  00017589.png   17149\n",
       "72823  00043388.png    1980\n",
       "\n",
       "[72824 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df=pd.read_csv('../train/label.txt',sep=':',header=None,names=['img_id','target']).sample(frac=1,random_state=42)\n",
    "train_df=pd.read_csv('../train/label.txt',sep=':',header=None,names=['img_id','target'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72824 entries, 0 to 72823\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   img_id  72824 non-null  object\n",
      " 1   target  72824 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8499     779\n",
       "1107     749\n",
       "7753     657\n",
       "14331    495\n",
       "17495    477\n",
       "        ... \n",
       "2656       1\n",
       "5288       1\n",
       "12839      1\n",
       "16072      1\n",
       "12250      1\n",
       "Name: target, Length: 19658, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#from PIL import Image\n",
    "import time\n",
    "import os\n",
    "# from model import ft_net, ft_net_dense, ft_net_NAS, PCB\n",
    "# from random_erasing import RandomErasing\n",
    "# import yaml\n",
    "import math\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fp16\n",
    "try:\n",
    "    from apex.fp16_utils import *\n",
    "    from apex import amp, optimizers\n",
    "except ImportError: # will be 3.x series\n",
    "    print('This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0')\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "fp16 = True\n",
    "DIR_INPUT = '../train'\n",
    "name = 'reid'# 模型保存的目录\n",
    "\n",
    "gpu_ids = [0,1]\n",
    "\n",
    "if not os.path.exists('./model/'+name):\n",
    "    os.mkdir('./model/'+name)\n",
    "    \n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "transforms_train = A.Compose([\n",
    "#     A.Resize(height=256, width=128, p=1.0),\n",
    "#     A.RandomResizedCrop(height=256, width=128, p=1.0),\n",
    "    A.Flip(),\n",
    "#     A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n",
    "\n",
    "    # Pixels\n",
    "#     A.OneOf([\n",
    "#         A.IAAEmboss(p=1.0),\n",
    "#         A.IAASharpen(p=1.0),\n",
    "#         A.Blur(p=1.0),\n",
    "#     ], p=0.5),\n",
    "\n",
    "    # Affine\n",
    "#     A.OneOf([\n",
    "#         A.ElasticTransform(p=1.0),\n",
    "#         A.IAAPiecewiseAffine(p=1.0)\n",
    "#     ], p=0.5),\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "transforms_valid = A.Compose([\n",
    "#     A.Resize(height=256, width=128, p=1.0),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReIDDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'img_id']\n",
    "\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = self.df.loc[idx, ['target']].values\n",
    "        labels = torch.from_numpy(labels.astype(np.int8))\n",
    "        labels = labels.squeeze(-1)\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    \n",
    "#读取速度更快\n",
    "class ReIDDataset2(Dataset):\n",
    "    \n",
    "    def __init__(self, df,targets, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.targets=targets\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'img_id']\n",
    "\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        labels=self.targets[idx]\n",
    "\n",
    "        labels=torch.tensor(labels)\n",
    "\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "# 为提交文件而设计的\n",
    "class ReIDDatasetTest(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        \n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_src =  self.df.loc[idx, 'img_id']\n",
    "\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "# class ReIDUnlabeledDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, df, transforms_weak=None, transforms_strong=None):\n",
    "    \n",
    "#         self.df = df\n",
    "#         self.transforms_weak=transforms_weak\n",
    "#         self.transforms_strong=transforms_strong\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.df.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'img_id'] + '.jpg'\n",
    "#         # print(image_src)\n",
    "#         image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "#         if self.transforms_strong:\n",
    "#             transformed = self.transforms_strong(image=image)\n",
    "#             image_new = transformed['image']\n",
    "#             if self.transforms_weak:\n",
    "#                 transformed = self.transforms_weak(image=image)\n",
    "#                 image = transformed['image']\n",
    "#             return image,image_new\n",
    "        \n",
    "#         return image,image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold,StratifiedShuffleSplit,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把原始训练数据分割成0.8:0.2比例的train和valid数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58259, 2) (58259,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val=train_test_split(train_df,train_df.target.values, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG=False#True\n",
    "if DEBUG:\n",
    "    X_train=X_train.sample(n=10000,random_state=0)\n",
    "    y_train=X_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#避免index error \n",
    "X_train.reset_index(inplace=True)\n",
    "X_val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = ReIDDataset(df=X_train, transforms=transforms_train)\n",
    "dataset_train = ReIDDataset2(df=X_train,targets=X_train.target.values, transforms=transforms_train)\n",
    "\n",
    "BATCH_SIZE=64#16\n",
    "VAL_BATCH_SIZE=4*BATCH_SIZE\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 256, 128]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#测试dataloader\n",
    "for x,y in dataloader_train:\n",
    "    print(x.size(),y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = ReIDDataset2(df=X_val,targets=X_val.target.values, transforms=transforms_train)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=VAL_BATCH_SIZE, num_workers=2, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ft_net, ft_net_dense, ft_net_NAS, PCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Save model\n",
    "#---------------------------\n",
    "\n",
    "def save_network(network, epoch_label):\n",
    "    save_filename = 'net_%s.pth'% epoch_label\n",
    "    save_path = os.path.join('./model',name,save_filename)\n",
    "    torch.save(network.cpu().state_dict(), save_path)\n",
    "    if torch.cuda.is_available():\n",
    "        network.cuda(gpu_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loss = {} # loss history\n",
    "y_loss['train'] = []\n",
    "y_loss['val'] = []\n",
    "y_err = {}\n",
    "y_err['train'] = []\n",
    "y_err['val'] = []\n",
    "\n",
    "\n",
    "WARM_EPOCH=5\n",
    "# NUM_EPOCHS=10\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    #best_model_wts = model.state_dict()\n",
    "    #best_acc = 0.0\n",
    "    warm_up = 0.1 # We start from the 0.1*lrRate\n",
    "    warm_iteration = round(len(dataset_train)/BATCH_SIZE)*WARM_EPOCH # first 5 epoch\n",
    "    best_acc=0.1\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print('Epoch {}/{}'.format(epoch, NUM_EPOCHS - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        scheduler.step()\n",
    "        model.train(True)  # Set model to training mode\n",
    "\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        # Iterate over data.\n",
    "        for data in dataloader_train:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            now_batch_size,c,h,w = inputs.shape\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "                       \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward            \n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if epoch<WARM_EPOCH : \n",
    "                warm_up = min(1.0, warm_up + 0.9 / warm_iteration)\n",
    "                loss *= warm_up\n",
    "\n",
    "            \n",
    "            if fp16: # we use optimier to backward loss\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            # for the new version like 0.4.0, 0.5.0 and 1.0.0\n",
    "            running_loss += loss.item() * now_batch_size\n",
    "            \n",
    "            running_corrects += float(torch.sum(preds == labels.data))\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset_train)\n",
    "        epoch_acc = running_corrects / len(dataset_train)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            'train', epoch_loss, epoch_acc))\n",
    "\n",
    "        y_loss['train'].append(epoch_loss)\n",
    "        y_err['train'].append(1.0-epoch_acc)  \n",
    "        \n",
    "        #valid the model\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader_valid:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                now_batch_size,c,h,w = inputs.shape\n",
    "                \n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * now_batch_size\n",
    "            \n",
    "                running_corrects += float(torch.sum(preds == labels.data))\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataset_valid)\n",
    "            epoch_acc = running_corrects / len(dataset_valid)\n",
    "            if best_acc<epoch_acc:\n",
    "                best_acc=epoch_acc\n",
    "                save_network(model, 'best')\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'valid', epoch_loss, epoch_acc))\n",
    "\n",
    "            y_loss['val'].append(epoch_loss)\n",
    "            y_err['val'].append(1.0-epoch_acc) \n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(last_model_wts)\n",
    "    save_network(model, 'last')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#densenet121\n",
    "model = ft_net_dense(19658, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft_net_dense(\n",
      "  (model): DenseNet(\n",
      "    (features): Sequential(\n",
      "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace=True)\n",
      "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (denseblock1): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock2): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock3): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition(\n",
      "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock4): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "    (fc): Sequential()\n",
      "  )\n",
      "  (classifier): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=19658, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "\n",
    "ignored_params = list(map(id, model.classifier.parameters() ))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params, model.parameters())\n",
    "optimizer_ft = optim.SGD([\n",
    "         {'params': base_params, 'lr': 0.1*lr},\n",
    "         {'params': model.classifier.parameters(), 'lr': lr}\n",
    "     ], weight_decay=5e-4, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 40 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=40, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Epoch 0/59\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomqin/anaconda3/envs/torch14/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.7904 Acc: 0.0311\n",
      "valid Loss: 9.0730 Acc: 0.0501\n",
      "Training complete in 4m 27s\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "train Loss: 3.2347 Acc: 0.0689\n",
      "valid Loss: 8.5803 Acc: 0.0876\n",
      "Training complete in 8m 50s\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 4.5084 Acc: 0.1081\n",
      "valid Loss: 8.1855 Acc: 0.1158\n",
      "Training complete in 13m 15s\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "train Loss: 5.5175 Acc: 0.1306\n",
      "valid Loss: 7.6837 Acc: 0.1283\n",
      "Training complete in 17m 38s\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "train Loss: 6.1294 Acc: 0.1539\n",
      "valid Loss: 7.1400 Acc: 0.1427\n",
      "Training complete in 22m 5s\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 5.8095 Acc: 0.2089\n",
      "valid Loss: 6.6117 Acc: 0.1749\n",
      "Training complete in 26m 34s\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "train Loss: 4.8271 Acc: 0.2969\n",
      "valid Loss: 6.1935 Acc: 0.2024\n",
      "Training complete in 31m 1s\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 3.8430 Acc: 0.4056\n",
      "valid Loss: 5.8883 Acc: 0.2324\n",
      "Training complete in 35m 28s\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "train Loss: 2.8545 Acc: 0.5573\n",
      "valid Loss: 5.7094 Acc: 0.2514\n",
      "Training complete in 39m 57s\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "train Loss: 1.8861 Acc: 0.7478\n",
      "valid Loss: 5.6422 Acc: 0.2649\n",
      "Training complete in 44m 25s\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "train Loss: 1.0657 Acc: 0.8993\n",
      "valid Loss: 5.6467 Acc: 0.2723\n",
      "Training complete in 48m 48s\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "train Loss: 0.5407 Acc: 0.9729\n",
      "valid Loss: 5.6603 Acc: 0.2829\n",
      "Training complete in 53m 11s\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "train Loss: 0.3099 Acc: 0.9921\n",
      "valid Loss: 5.6527 Acc: 0.2825\n",
      "Training complete in 57m 34s\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "train Loss: 0.2278 Acc: 0.9949\n",
      "valid Loss: 5.6149 Acc: 0.2860\n",
      "Training complete in 61m 58s\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "train Loss: 0.2013 Acc: 0.9956\n",
      "valid Loss: 5.6008 Acc: 0.2882\n",
      "Training complete in 66m 20s\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "train Loss: 0.1876 Acc: 0.9960\n",
      "valid Loss: 5.5775 Acc: 0.2915\n",
      "Training complete in 70m 44s\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1805 Acc: 0.9963\n",
      "valid Loss: 5.5878 Acc: 0.2842\n",
      "Training complete in 75m 7s\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9963\n",
      "valid Loss: 5.5419 Acc: 0.2919\n",
      "Training complete in 79m 31s\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "train Loss: 0.1751 Acc: 0.9965\n",
      "valid Loss: 5.5437 Acc: 0.2901\n",
      "Training complete in 83m 53s\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1721 Acc: 0.9965\n",
      "valid Loss: 5.5475 Acc: 0.2901\n",
      "Training complete in 88m 12s\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9969\n",
      "valid Loss: 5.5374 Acc: 0.2912\n",
      "Training complete in 92m 30s\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "train Loss: 0.1705 Acc: 0.9965\n",
      "valid Loss: 5.5258 Acc: 0.2895\n",
      "Training complete in 96m 46s\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1663 Acc: 0.9966\n",
      "valid Loss: 5.5146 Acc: 0.2929\n",
      "Training complete in 101m 2s\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "train Loss: 0.1637 Acc: 0.9966\n",
      "valid Loss: 5.5379 Acc: 0.2864\n",
      "Training complete in 105m 14s\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "train Loss: 0.1651 Acc: 0.9965\n",
      "valid Loss: 5.5293 Acc: 0.2932\n",
      "Training complete in 109m 27s\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1607 Acc: 0.9968\n",
      "valid Loss: 5.5148 Acc: 0.2955\n",
      "Training complete in 113m 39s\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9965\n",
      "valid Loss: 5.5081 Acc: 0.2955\n",
      "Training complete in 117m 51s\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9969\n",
      "valid Loss: 5.5160 Acc: 0.2942\n",
      "Training complete in 122m 3s\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9965\n",
      "valid Loss: 5.5149 Acc: 0.2979\n",
      "Training complete in 126m 17s\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1568 Acc: 0.9968\n",
      "valid Loss: 5.5172 Acc: 0.2939\n",
      "Training complete in 130m 30s\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1561 Acc: 0.9968\n",
      "valid Loss: 5.5238 Acc: 0.2935\n",
      "Training complete in 134m 46s\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9969\n",
      "valid Loss: 5.5109 Acc: 0.2945\n",
      "Training complete in 139m 2s\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1529 Acc: 0.9969\n",
      "valid Loss: 5.5011 Acc: 0.2977\n",
      "Training complete in 143m 18s\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "train Loss: 0.1516 Acc: 0.9970\n",
      "valid Loss: 5.5061 Acc: 0.2958\n",
      "Training complete in 147m 33s\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "train Loss: 0.1515 Acc: 0.9966\n",
      "valid Loss: 5.5128 Acc: 0.2954\n",
      "Training complete in 151m 50s\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9968\n",
      "valid Loss: 5.5099 Acc: 0.2974\n",
      "Training complete in 156m 7s\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1496 Acc: 0.9968\n",
      "valid Loss: 5.5068 Acc: 0.2976\n",
      "Training complete in 160m 23s\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "train Loss: 0.1490 Acc: 0.9968\n",
      "valid Loss: 5.5045 Acc: 0.2963\n",
      "Training complete in 164m 38s\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "train Loss: 0.1485 Acc: 0.9970\n",
      "valid Loss: 5.4954 Acc: 0.2963\n",
      "Training complete in 168m 53s\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9978\n",
      "valid Loss: 5.4822 Acc: 0.2993\n",
      "Training complete in 173m 8s\n",
      "\n",
      "Epoch 40/59\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9978\n",
      "valid Loss: 5.4728 Acc: 0.2992\n",
      "Training complete in 177m 22s\n",
      "\n",
      "Epoch 41/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1027 Acc: 0.9975\n",
      "valid Loss: 5.4803 Acc: 0.2976\n",
      "Training complete in 181m 37s\n",
      "\n",
      "Epoch 42/59\n",
      "----------\n",
      "train Loss: 0.1030 Acc: 0.9976\n",
      "valid Loss: 5.4744 Acc: 0.2987\n",
      "Training complete in 185m 51s\n",
      "\n",
      "Epoch 43/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1039 Acc: 0.9974\n",
      "valid Loss: 5.4814 Acc: 0.2974\n",
      "Training complete in 190m 7s\n",
      "\n",
      "Epoch 44/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1051 Acc: 0.9974\n",
      "valid Loss: 5.4740 Acc: 0.3002\n",
      "Training complete in 194m 23s\n",
      "\n",
      "Epoch 45/59\n",
      "----------\n",
      "train Loss: 0.1053 Acc: 0.9976\n",
      "valid Loss: 5.4790 Acc: 0.2998\n",
      "Training complete in 198m 38s\n",
      "\n",
      "Epoch 46/59\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9978\n",
      "valid Loss: 5.4822 Acc: 0.2972\n",
      "Training complete in 202m 53s\n",
      "\n",
      "Epoch 47/59\n",
      "----------\n",
      "train Loss: 0.1080 Acc: 0.9978\n",
      "valid Loss: 5.4754 Acc: 0.2992\n",
      "Training complete in 207m 8s\n",
      "\n",
      "Epoch 48/59\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9977\n",
      "valid Loss: 5.4806 Acc: 0.3002\n",
      "Training complete in 211m 22s\n",
      "\n",
      "Epoch 49/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1107 Acc: 0.9977\n",
      "valid Loss: 5.4785 Acc: 0.2985\n",
      "Training complete in 215m 37s\n",
      "\n",
      "Epoch 50/59\n",
      "----------\n",
      "train Loss: 0.1114 Acc: 0.9976\n",
      "valid Loss: 5.4805 Acc: 0.3001\n",
      "Training complete in 219m 51s\n",
      "\n",
      "Epoch 51/59\n",
      "----------\n",
      "train Loss: 0.1122 Acc: 0.9975\n",
      "valid Loss: 5.4808 Acc: 0.2988\n",
      "Training complete in 224m 7s\n",
      "\n",
      "Epoch 52/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1131 Acc: 0.9978\n",
      "valid Loss: 5.4781 Acc: 0.2996\n",
      "Training complete in 228m 23s\n",
      "\n",
      "Epoch 53/59\n",
      "----------\n",
      "train Loss: 0.1146 Acc: 0.9973\n",
      "valid Loss: 5.4885 Acc: 0.2982\n",
      "Training complete in 232m 39s\n",
      "\n",
      "Epoch 54/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1148 Acc: 0.9975\n",
      "valid Loss: 5.4820 Acc: 0.3004\n",
      "Training complete in 236m 54s\n",
      "\n",
      "Epoch 55/59\n",
      "----------\n",
      "train Loss: 0.1161 Acc: 0.9972\n",
      "valid Loss: 5.4817 Acc: 0.2991\n",
      "Training complete in 241m 9s\n",
      "\n",
      "Epoch 56/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1163 Acc: 0.9976\n",
      "valid Loss: 5.4844 Acc: 0.2985\n",
      "Training complete in 245m 24s\n",
      "\n",
      "Epoch 57/59\n",
      "----------\n",
      "train Loss: 0.1178 Acc: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 5.4795 Acc: 0.2987\n",
      "Training complete in 249m 42s\n",
      "\n",
      "Epoch 58/59\n",
      "----------\n",
      "train Loss: 0.1183 Acc: 0.9976\n",
      "valid Loss: 5.4771 Acc: 0.2990\n",
      "Training complete in 253m 57s\n",
      "\n",
      "Epoch 59/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 0.1188 Acc: 0.9976\n",
      "valid Loss: 5.4803 Acc: 0.2988\n",
      "Training complete in 258m 12s\n",
      "\n",
      "Training complete in 258m 12s\n"
     ]
    }
   ],
   "source": [
    "# model to gpu\n",
    "model = model.cuda()\n",
    "if fp16:\n",
    "    model, optimizer_ft = amp.initialize(model, optimizer_ft, opt_level = \"O1\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "NUM_EPOCHS=60\n",
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model/{}/net_best.pth'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 5.4814 Acc: 0.2993\n"
     ]
    }
   ],
   "source": [
    "#valid the model\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in dataloader_valid:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        now_batch_size,c,h,w = inputs.shape\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * now_batch_size\n",
    "\n",
    "        running_corrects += float(torch.sum(preds == labels.data))\n",
    "\n",
    "    epoch_loss = running_loss / len(dataset_valid)\n",
    "    epoch_acc = running_corrects / len(dataset_valid)\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        'valid', epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通拿query的一张图片，在gallery目录里查询符合这个query图片的可能图片（可能存在多张）\n",
    "'''\n",
    "mAP(mean average precision)：反应检索的人在数据库中所有正确的图片排在排序列表前面的程度，能更加全面的衡量ReID算法的性能。\n",
    "如下图，假设该检索行人在gallery中有10张图片，在检索的list中位置（rank）分别为1、2、3、4、5、6、7、8、9，\n",
    "则ap为(1/ 1 + 2 / 2 + 3 / 3 + 4 / 4 + 5 / 5 + 6 / 6 + 7 / 7 + 8 / 8 + 9 / 9) / 10 = 0.90；\n",
    "ap较大时，该行人的检索结果都相对靠前，对所有query的ap取平均值得到mAP\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_network(model, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to test mode\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(index, good_index, junk_index):\n",
    "    ap = 0\n",
    "    cmc = torch.IntTensor(len(index)).zero_()\n",
    "    if good_index.size==0:   # if empty\n",
    "        cmc[0] = -1\n",
    "        return ap,cmc\n",
    "\n",
    "    # remove junk_index\n",
    "    mask = np.in1d(index, junk_index, invert=True)\n",
    "    index = index[mask]\n",
    "\n",
    "    # find good_index index\n",
    "    ngood = len(good_index)\n",
    "    mask = np.in1d(index, good_index)\n",
    "    rows_good = np.argwhere(mask==True)\n",
    "    rows_good = rows_good.flatten()\n",
    "    \n",
    "    cmc[rows_good[0]:] = 1\n",
    "    for i in range(ngood):\n",
    "        d_recall = 1.0/ngood\n",
    "        precision = (i+1)*1.0/(rows_good[i]+1)\n",
    "        if rows_good[i]!=0:\n",
    "            old_precision = i*1.0/rows_good[i]\n",
    "        else:\n",
    "            old_precision=1.0\n",
    "        ap = ap + d_recall*(old_precision + precision)/2\n",
    "\n",
    "    return ap, cmc\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Evaluate\n",
    "def evaluate(qf,ql,qc,gf,gl,gc):\n",
    "    query = qf.view(-1,1)\n",
    "    # print(query.shape)\n",
    "    score = torch.mm(gf,query)\n",
    "    score = score.squeeze(1).cpu()\n",
    "    score = score.numpy()\n",
    "    # predict index\n",
    "    index = np.argsort(score)  #from small to large\n",
    "    index = index[::-1]\n",
    "    # index = index[0:2000]\n",
    "    # good index\n",
    "    query_index = np.argwhere(gl==ql)\n",
    "    camera_index = np.argwhere(gc==qc)\n",
    "\n",
    "    good_index = np.setdiff1d(query_index, camera_index, assume_unique=True)\n",
    "    junk_index1 = np.argwhere(gl==-1)\n",
    "    junk_index2 = np.intersect1d(query_index, camera_index)\n",
    "    junk_index = np.append(junk_index2, junk_index1) #.flatten())\n",
    "    \n",
    "    CMC_tmp = compute_mAP(index, good_index, junk_index)\n",
    "    return CMC_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model,dataloaders):\n",
    "    features = torch.FloatTensor()\n",
    "    count = 0\n",
    "    for data in dataloaders:\n",
    "        img=data.cuda()          \n",
    "        outputs = model(img) \n",
    "        features = torch.cat((features,outputs.data.cpu()), 0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query（查询）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../image_A/query/00000000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../image_A/query/00000001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../image_A/query/00000002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../image_A/query/00000003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../image_A/query/00000004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>../image_A/query/00002895.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>../image_A/query/00002896.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>../image_A/query/00002897.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>../image_A/query/00002898.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>../image_A/query/00002899.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             img_id\n",
       "0     ../image_A/query/00000000.png\n",
       "1     ../image_A/query/00000001.png\n",
       "2     ../image_A/query/00000002.png\n",
       "3     ../image_A/query/00000003.png\n",
       "4     ../image_A/query/00000004.png\n",
       "...                             ...\n",
       "2895  ../image_A/query/00002895.png\n",
       "2896  ../image_A/query/00002896.png\n",
       "2897  ../image_A/query/00002897.png\n",
       "2898  ../image_A/query/00002898.png\n",
       "2899  ../image_A/query/00002899.png\n",
       "\n",
       "[2900 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#query\n",
    "query_list=glob.glob(r'../image_A/query/*.png')\n",
    "query_name_list=[]\n",
    "for file_path   in query_list:\n",
    "    file_name=file_path\n",
    "    query_name_list.append(file_name)\n",
    "\n",
    "query_df=pd.DataFrame(data={'img_id':query_name_list})\n",
    "query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_query = ReIDDatasetTest(df=query_df, transforms=transforms_train)\n",
    "dataloader_query = DataLoader(dataset_query, batch_size=VAL_BATCH_SIZE, num_workers=2, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "for img in dataloader_query:\n",
    "    print(img.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gallery（待搜索图库）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../image_A/gallery/00000000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../image_A/gallery/00000006.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../image_A/gallery/00000009.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../image_A/gallery/00000012.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../image_A/gallery/00000016.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40461</th>\n",
       "      <td>../image_A/gallery/00143698.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40462</th>\n",
       "      <td>../image_A/gallery/00143707.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40463</th>\n",
       "      <td>../image_A/gallery/00143708.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40464</th>\n",
       "      <td>../image_A/gallery/00143710.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40465</th>\n",
       "      <td>../image_A/gallery/00143711.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40466 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                img_id\n",
       "0      ../image_A/gallery/00000000.png\n",
       "1      ../image_A/gallery/00000006.png\n",
       "2      ../image_A/gallery/00000009.png\n",
       "3      ../image_A/gallery/00000012.png\n",
       "4      ../image_A/gallery/00000016.png\n",
       "...                                ...\n",
       "40461  ../image_A/gallery/00143698.png\n",
       "40462  ../image_A/gallery/00143707.png\n",
       "40463  ../image_A/gallery/00143708.png\n",
       "40464  ../image_A/gallery/00143710.png\n",
       "40465  ../image_A/gallery/00143711.png\n",
       "\n",
       "[40466 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gallery\n",
    "gallery_list=glob.glob(r'../image_A/gallery/*.png')\n",
    "gallery_name_list=[]\n",
    "for file_path   in gallery_list:\n",
    "    #     file_name=file_path.split('/')[-1]\n",
    "    file_name=file_path\n",
    "    gallery_name_list.append(file_name)\n",
    "#     break\n",
    "# print((query_list))\n",
    "gallery_df=pd.DataFrame(data={'img_id':gallery_name_list})\n",
    "gallery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gallery字典，用于根据索引反向获得对应的图片id\n",
    "gallery_dict={}\n",
    "for i,file in enumerate(gallery_df.img_id.values):\n",
    "    gallery_dict[i]=file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gallery = ReIDDatasetTest(df=gallery_df, transforms=transforms_train)\n",
    "dataloader_gallery = DataLoader(dataset_gallery, batch_size=VAL_BATCH_SIZE, num_workers=2, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000.png'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽取query特征和gallery特征，准备计算距离做排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature\n",
    "with torch.no_grad():\n",
    "    query_feature = extract_feature(model,dataloader_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2900, 19658])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feature.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature\n",
    "with torch.no_grad():\n",
    "    gallery_feature = extract_feature(model,dataloader_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40466, 19658])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_feature.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = query_feature.size(0), gallery_feature.size(0)\n",
    "distmat = torch.pow(query_feature, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "          torch.pow(gallery_feature, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "distmat.addmm_(1, -2, query_feature, gallery_feature.t())\n",
    "distmat = distmat.numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序取前200\n",
    "indices = np.argsort(distmat,1)\n",
    "indices_200 = indices[:,:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2900, 40466), (2900, 40466))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmat.shape,indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37010.645, 59662.06 , 47878.03 , ..., 33554.715, 46645.082,\n",
       "        62608.848], dtype=float32),\n",
       " array([37225, 32001, 36112, ...,  2275,  5389, 13564]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmat[0],indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2900, 200)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_200.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成用来导出json的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_name_list\n",
    "new_dict={}\n",
    "for j,a in enumerate(indices_200.tolist()):\n",
    "    line_arr=[]\n",
    "#     counter+=1\n",
    "    for i in a:\n",
    "        line_arr.append(gallery_dict[i])\n",
    "    key=query_name_list[j].split('/')[-1]\n",
    "\n",
    "    new_dict[key]=list(line_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_name_list\n",
    "# new_dict={}\n",
    "# with open(\"submission_0826.json\",\"w\",encoding='utf-8') as fout:\n",
    "#     fout.write('{')\n",
    "#     for j,a in enumerate(indices_200.tolist()):\n",
    "#         line_arr=[]\n",
    "#         counter+=1\n",
    "#         str_arr=''\n",
    "#         for i in a:\n",
    "#             line_arr.append(gallery_dict[i])\n",
    "#             str_arr+='\\\"{}\\\",'.format(gallery_dict[i])\n",
    "#         key=query_name_list[j].split('/')[-1]\n",
    "# #         line_str='\\\"{}\\\":[{}]\\n'.format(key,str_arr[:-1])\n",
    "#         line_str='\\\"{}\\\":[{}]'.format(key,str_arr[:-1])\n",
    "\n",
    "#         fout.write(line_str+',')\n",
    "#     fout.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载入文件完成...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"submission_0826.json\",\"w\") as f:\n",
    "    json.dump(new_dict,f)\n",
    "    print(\"加载入文件完成...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"00000000.png\": [\"00132168.png\", \"00113784.png\", \"00128367.png\", \"00111189.png\", \"00120209.png\", \"00046388.png\", \"00114940.png\", \"00005929.png\", \"00109199.png\", \"00051029.png\", \"00079075.png\", \"00043566.png\", \"00092131.png\", \"00043037.png\", \"00088203.png\", \"00043784.png\", \"00129853.png\", \"00122116.png\", \"00064475.png\", \"00090732.png\", \"00106857.png\", \"00088026.png\", \"00082180.png\", \"00125995.png\", \"00009080.png\", \"00140252.png\", \"00100484.png\", \"00010559.png\", \"00041469.png\", \"00028894.png\", \"00109299.png\", \"00136194.png\", \"00104401.png\", \"00024915.png\", \"00051067.png\", \"00012766.png\", \"00003180.png\", \"00059144.png\", \"00012197.png\", \"00140366.png\", \"00118597.png\", \"00049724.png\", \"00011504.png\", \"00131739.png\", \"00103689.png\", \"00002738.png\", \"00011825.png\", \"00019184.png\", \"00106560.png\", \"00127521.png\", \"00127994.png\", \"00097701.png\", \"00024636.png\", \"00001981.png\", \"00035005.png\", \"00053709.png\", \"00004009.png\", \"00046018.png\", \"00078154.png\", \"00075794.png\", \"00124130.png\", \"00000860.png\", \"00057798.png\", \"00140684.png\", \"00031668.png\", \"00100675.png\", \"00016638.png\", \"00007576.png\", \"00047459.png\", \"00015968.png\", \"00106315.png\", \"00050469.png\", \"00042666.png\", \"00122487.png\", \"00123087.png\", \"00109700.png\", \"00107910.png\", \"00017638.png\", \"00133831.png\", \"00005245.png\", \"00060123.png\", \"00047768.png\", \"00032852.png\", \"00012721.png\", \"00121201.png\", \"00140004.png\", \"00074205.png\", \"00061528.png\", \"00035549.png\", \"00018648.png\", \"00037540.png\", \"00066869.png\", \"00074859.png\", \"00041814.png\", \"00011104.png\", \"00087617.png\", \"00005109.png\", \"00116645.png\", \"00003221.png\", \"00030997.png\", \"00034542.png\", \"00062011.png\", \"00092937.png\", \"00069891.png\", \"00089557.png\", \"00118153.png\", \"00039597.png\", \"00142508.png\", \"00126328.png\", \"00075539.png\", \"00121001.png\", \"00067853.png\", \"00050020.png\", \"00121415.png\", \"00073803.png\", \"00039762.png\", \"00017844.png\", \"00021108.png\", \"00054979.png\", \"00111634.png\", \"00018051.png\", \"00029966.png\", \"00024931.png\", \"00132200.png\", \"00095951.png\", \"00086191.png\", \"00005972.png\", \"00025587.png\", \"00002492.png\", \"00119033.png\", \"00132792.png\", \"00031697.png\", \"00012383.png\", \"00094739.png\", \"00022928.png\", \"00132570.png\", \"00078708.png\", \"00017731.png\", \"00048924.png\", \"00007632.png\", \"00078599.png\", \"00129670.png\", \"00000965.png\", \"00008179.png\", \"00061505.png\", \"00098053.png\", \"00135802.png\", \"00058378.png\", \"00128943.png\", \"00062950.png\", \"00119762.png\", \"00091784.png\", \"00072728.png\", \"00091237.png\", \"00143285.png\", \"00014698.png\", \"00021060.png\", \"00100761.png\", \"00068699.png\", \"00030329.png\", \"00058604.png\", \"00079925.png\", \"00059436.png\", \"00084366.png\", \"00132260.png\", \"00022882.png\", \"00114022.png\", \"00001084.png\", \"00067574.png\", \"00064491.png\", \"00128155.png\", \"00095136.png\", \"00011377.png\", \"00117090.png\", \"00110531.png\", \"00061215.png\", \"00018498.png\", \"00022711.png\", \"00123008.png\", \"00112465.png\", \"00106407.png\", \"00135209.png\", \"00033187.png\", \"00005268.png\", \"00091021.png\", \"00039549.png\", \"00077792.png\", \"00039211.png\", \"00120311.png\", \"00045491.png\", \"00142699.png\", \"00049582.png\", \"00049419.png\", \"00100878.png\", \"00135243.png\", \"00143708.png\", \"00018954.png\", \"00088963.png\", \"00074817.png\", \"00017814.png\"], \"00000001.png\": [\"00002484.png\", \"00056136.png\", \"00027984.png\", \"00116681.png\", \"00141940.png\", \"00091605.png\", \"00078104.png\", \"00113730.png\", \"00041735.png\", \"00025259.png\", \"00024931.png\", \"00103676.png\", \"00109431.png\", \"00006316.png\", \"00090347.png\", \"00070238.png\", \"00046368.png\", \"00008814.png\", \"00135243.png\", \"00001981.png\", \"00108945.png\", \"00040010.png\", \"00095637.png\", \"00118646.png\", \"00043564.png\", \"00137859.png\", \"00023609.png\", \"00022882.png\", \"00121415.png\", \"00132137.png\", \"00052705.png\", \"00083938.png\", \"00014731.png\", \"00053213.png\", \"00025384.png\", \"00026006.png\", \"00041054.png\", \"00127587.png\", \"00101765.png\", \"00125496.png\", \"00106211.png\", \"00024636.png\", \"00018648.png\", \"00122900.png\", \"00128973.png\", \"00073154.png\", \"00099502.png\", \"00066869.png\", \"00001146.png\", \"00120531.png\", \"00022018.png\", \"00068898.png\", \"00000143.png\", \"00011597.png\", \"00115022.png\", \"00086123.png\", \"00139138.png\", \"00074905.png\", \"00008271.png\", \"00064479.png\", \"00129331.png\", \"00024173.png\", \"00012383.png\", \"00015620.png\", \"00124543.png\", \"00024254.png\", \"00109299.png\", \"00036177.png\", \"00081242.png\", \"00084489.png\", \"00093450.png\", \"00118153.png\", \"00095392.png\", \"00052664.png\", \"00045169.png\", \"00132570.png\", \"00109868.png\", \"00121531.png\", \"00100313.png\", \"00139670.png\", \"00115074.png\", \"00031571.png\", \"00023126.png\", \"00094933.png\", \"00055986.png\", \"00103972.png\", \"00142773.png\", \"00117090.png\", \"00040159.png\", \"00078575.png\", \"00030544.png\", \"00074297.png\", \"00118484.png\", \"00031668.png\", \"00099394.png\", \"00100919.png\", \"00140649.png\", \"00114182.png\", \"00061118.png\", \"00066404.png\", \"00051765.png\", \"00097836.png\", \"00039549.png\", \"00108473.png\", \"00096806.png\", \"00118838.png\", \"00140712.png\", \"00138351.png\", \"00024406.png\", \"00135577.png\", \"00069675.png\", \"00005258.png\", \"00076877.png\", \"00123461.png\", \"00057762.png\", \"00130909.png\", \"00067806.png\", \"00011280.png\", \"00024340.png\", \"00126777.png\", \"00104214.png\", \"00040932.png\", \"00121201.png\", \"00053679.png\", \"00137452.png\", \"00050169.png\", \"00017814.png\", \"00110034.png\", \"00095340.png\", \"00119830.png\", \"00033107.png\", \"00101647.png\", \"00091657.png\", \"00107910.png\", \"00126372.png\", \"00094005.png\", \"00117865.png\", \"00021321.png\", \"00095848.png\", \"00066102.png\", \"00071357.png\", \"00019509.png\", \"00088856.png\", \"00039331.png\", \"00105683.png\", \"00014898.png\", \"00051427.png\", \"00086993.png\", \"00095178.png\", \"00040295.png\", \"00090947.png\", \"00123722.png\", \"00033624.png\", \"00086670.png\", \"00012246.png\", \"00061857.png\", \"00124489.png\", \"00041678.png\", \"00090025.png\", \"00064286.png\", \"00076711.png\", \"00073803.png\", \"00005151.png\", \"00016638.png\", \"00057179.png\", \"00129591.png\", \"00008544.png\", \"00123258.png\", \"00038415.png\", \"00080350.png\", \"00141533.png\", \"00141425.png\", \"00003890.pn\n"
     ]
    }
   ],
   "source": [
    "#检查生成的文件\n",
    "with open(\"submission_0826.json\",\"r\") as fin:\n",
    "    for line in fin:\n",
    "        print(line[:6000])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')\n",
    "#lb 0.235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
