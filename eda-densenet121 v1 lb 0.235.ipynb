{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "20200826\n",
    "这是一个start code,用来学习reid项目。\n",
    "仅仅使用官方给的train数据进行训练，没有数据增强，没有使用外部数据。\n",
    "使用densenet121网络训练和抽取特征。\n",
    "使用fp16进行训练。\n",
    "没有re-ranking。\n",
    "lb 0.2357\n",
    "\n",
    "代码的基本框架来源于郑哲东大神的开源项目：https://github.com/layumi/Person_reID_baseline_pytorch\n",
    "环境：pytorch 1.4\n",
    "训练10个epoch，就能得到0.23x的分数。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00040591.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066284.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00025569.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00024054.png</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00028221.png</td>\n",
       "      <td>4664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72819</th>\n",
       "      <td>00024418.png</td>\n",
       "      <td>4332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72820</th>\n",
       "      <td>00029689.png</td>\n",
       "      <td>15371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72821</th>\n",
       "      <td>00026579.png</td>\n",
       "      <td>15371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72822</th>\n",
       "      <td>00017589.png</td>\n",
       "      <td>17149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72823</th>\n",
       "      <td>00043388.png</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             img_id  target\n",
       "0      00040591.png   15178\n",
       "1      00066284.png   15178\n",
       "2      00025569.png   15178\n",
       "3      00024054.png   15178\n",
       "4      00028221.png    4664\n",
       "...             ...     ...\n",
       "72819  00024418.png    4332\n",
       "72820  00029689.png   15371\n",
       "72821  00026579.png   15371\n",
       "72822  00017589.png   17149\n",
       "72823  00043388.png    1980\n",
       "\n",
       "[72824 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df=pd.read_csv('../train/label.txt',sep=':',header=None,names=['img_id','target']).sample(frac=1,random_state=42)\n",
    "train_df=pd.read_csv('../train/label.txt',sep=':',header=None,names=['img_id','target'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72824 entries, 0 to 72823\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   img_id  72824 non-null  object\n",
      " 1   target  72824 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8499     779\n",
       "1107     749\n",
       "7753     657\n",
       "14331    495\n",
       "17495    477\n",
       "        ... \n",
       "2656       1\n",
       "5288       1\n",
       "12839      1\n",
       "16072      1\n",
       "12250      1\n",
       "Name: target, Length: 19658, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#from PIL import Image\n",
    "import time\n",
    "import os\n",
    "# from model import ft_net, ft_net_dense, ft_net_NAS, PCB\n",
    "# from random_erasing import RandomErasing\n",
    "# import yaml\n",
    "import math\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fp16\n",
    "try:\n",
    "    from apex.fp16_utils import *\n",
    "    from apex import amp, optimizers\n",
    "except ImportError: # will be 3.x series\n",
    "    print('This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0')\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "fp16 = True\n",
    "DIR_INPUT = '../train'\n",
    "name = 'reid'# 模型保存的目录\n",
    "\n",
    "gpu_ids = [0,1]\n",
    "\n",
    "if not os.path.exists('./model/'+name):\n",
    "    os.mkdir('./model/'+name)\n",
    "    \n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "transforms_train = A.Compose([\n",
    "#     A.Resize(height=256, width=128, p=1.0),\n",
    "#     A.RandomResizedCrop(height=256, width=128, p=1.0),\n",
    "#     A.Flip(),\n",
    "#     A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n",
    "\n",
    "    # Pixels\n",
    "#     A.OneOf([\n",
    "#         A.IAAEmboss(p=1.0),\n",
    "#         A.IAASharpen(p=1.0),\n",
    "#         A.Blur(p=1.0),\n",
    "#     ], p=0.5),\n",
    "\n",
    "    # Affine\n",
    "#     A.OneOf([\n",
    "#         A.ElasticTransform(p=1.0),\n",
    "#         A.IAAPiecewiseAffine(p=1.0)\n",
    "#     ], p=0.5),\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "transforms_valid = A.Compose([\n",
    "#     A.Resize(height=256, width=128, p=1.0),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReIDDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'img_id']\n",
    "\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = self.df.loc[idx, ['target']].values\n",
    "        labels = torch.from_numpy(labels.astype(np.int8))\n",
    "        labels = labels.squeeze(-1)\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    \n",
    "#读取速度更快\n",
    "class ReIDDataset2(Dataset):\n",
    "    \n",
    "    def __init__(self, df,targets, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.targets=targets\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'img_id']\n",
    "\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        labels=self.targets[idx]\n",
    "\n",
    "        labels=torch.tensor(labels)\n",
    "\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "# 为提交文件而设计的\n",
    "class ReIDDatasetTest(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        \n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_src =  self.df.loc[idx, 'img_id']\n",
    "\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "# class ReIDUnlabeledDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, df, transforms_weak=None, transforms_strong=None):\n",
    "    \n",
    "#         self.df = df\n",
    "#         self.transforms_weak=transforms_weak\n",
    "#         self.transforms_strong=transforms_strong\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.df.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'img_id'] + '.jpg'\n",
    "#         # print(image_src)\n",
    "#         image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "#         if self.transforms_strong:\n",
    "#             transformed = self.transforms_strong(image=image)\n",
    "#             image_new = transformed['image']\n",
    "#             if self.transforms_weak:\n",
    "#                 transformed = self.transforms_weak(image=image)\n",
    "#                 image = transformed['image']\n",
    "#             return image,image_new\n",
    "        \n",
    "#         return image,image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold,StratifiedShuffleSplit,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把原始训练数据分割成0.8:0.2比例的train和valid数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58259, 2) (58259,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val=train_test_split(train_df,train_df.target.values, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEBUG=False#True\n",
    "if DEBUG:\n",
    "    X_train=X_train.sample(n=10000,random_state=0)\n",
    "    y_train=X_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#避免index error \n",
    "X_train.reset_index(inplace=True)\n",
    "X_val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = ReIDDataset(df=X_train, transforms=transforms_train)\n",
    "dataset_train = ReIDDataset2(df=X_train,targets=X_train.target.values, transforms=transforms_train)\n",
    "\n",
    "BATCH_SIZE=64#16\n",
    "VAL_BATCH_SIZE=4*BATCH_SIZE\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 256, 128]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#测试dataloader\n",
    "for x,y in dataloader_train:\n",
    "    print(x.size(),y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = ReIDDataset2(df=X_val,targets=X_val.target.values, transforms=transforms_train)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=VAL_BATCH_SIZE, num_workers=2, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ft_net, ft_net_dense, ft_net_NAS, PCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Save model\n",
    "#---------------------------\n",
    "\n",
    "def save_network(network, epoch_label):\n",
    "    save_filename = 'net_%s.pth'% epoch_label\n",
    "    save_path = os.path.join('./model',name,save_filename)\n",
    "    torch.save(network.cpu().state_dict(), save_path)\n",
    "    if torch.cuda.is_available():\n",
    "        network.cuda(gpu_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loss = {} # loss history\n",
    "y_loss['train'] = []\n",
    "y_loss['val'] = []\n",
    "y_err = {}\n",
    "y_err['train'] = []\n",
    "y_err['val'] = []\n",
    "\n",
    "\n",
    "WARM_EPOCH=5\n",
    "# NUM_EPOCHS=10\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    #best_model_wts = model.state_dict()\n",
    "    #best_acc = 0.0\n",
    "    warm_up = 0.1 # We start from the 0.1*lrRate\n",
    "    warm_iteration = round(len(dataset_train)/BATCH_SIZE)*WARM_EPOCH # first 5 epoch\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print('Epoch {}/{}'.format(epoch, NUM_EPOCHS - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        scheduler.step()\n",
    "        model.train(True)  # Set model to training mode\n",
    "\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        # Iterate over data.\n",
    "        for data in dataloader_train:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            now_batch_size,c,h,w = inputs.shape\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "                       \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward            \n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if epoch<WARM_EPOCH : \n",
    "                warm_up = min(1.0, warm_up + 0.9 / warm_iteration)\n",
    "                loss *= warm_up\n",
    "\n",
    "            \n",
    "            if fp16: # we use optimier to backward loss\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            # for the new version like 0.4.0, 0.5.0 and 1.0.0\n",
    "            running_loss += loss.item() * now_batch_size\n",
    "            \n",
    "            running_corrects += float(torch.sum(preds == labels.data))\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset_train)\n",
    "        epoch_acc = running_corrects / len(dataset_train)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            'train', epoch_loss, epoch_acc))\n",
    "\n",
    "        y_loss['train'].append(epoch_loss)\n",
    "        y_err['train'].append(1.0-epoch_acc)  \n",
    "        \n",
    "        #valid the model\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader_valid:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                now_batch_size,c,h,w = inputs.shape\n",
    "                \n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * now_batch_size\n",
    "            \n",
    "                running_corrects += float(torch.sum(preds == labels.data))\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataset_valid)\n",
    "            epoch_acc = running_corrects / len(dataset_valid)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'valid', epoch_loss, epoch_acc))\n",
    "\n",
    "            y_loss['val'].append(epoch_loss)\n",
    "            y_err['val'].append(1.0-epoch_acc) \n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(last_model_wts)\n",
    "    save_network(model, 'last')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#densenet121\n",
    "model = ft_net_dense(19658, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft_net_dense(\n",
      "  (model): DenseNet(\n",
      "    (features): Sequential(\n",
      "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace=True)\n",
      "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (denseblock1): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock2): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock3): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition(\n",
      "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock4): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "    (fc): Sequential()\n",
      "  )\n",
      "  (classifier): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=19658, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "\n",
    "ignored_params = list(map(id, model.classifier.parameters() ))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params, model.parameters())\n",
    "optimizer_ft = optim.SGD([\n",
    "         {'params': base_params, 'lr': 0.1*lr},\n",
    "         {'params': model.classifier.parameters(), 'lr': lr}\n",
    "     ], weight_decay=5e-4, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 40 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=40, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Epoch 0/59\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomqin/anaconda3/envs/torch14/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.7837 Acc: 0.0339\n",
      "valid Loss: 9.0218 Acc: 0.0558\n",
      "Training complete in 3m 44s\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "train Loss: 3.2036 Acc: 0.0808\n",
      "valid Loss: 8.5045 Acc: 0.1023\n",
      "Training complete in 7m 20s\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 4.4383 Acc: 0.1247\n",
      "valid Loss: 8.1080 Acc: 0.1279\n",
      "Training complete in 10m 56s\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "train Loss: 5.3931 Acc: 0.1475\n",
      "valid Loss: 7.6077 Acc: 0.1366\n",
      "Training complete in 14m 34s\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "train Loss: 5.8904 Acc: 0.1790\n",
      "valid Loss: 7.0424 Acc: 0.1574\n",
      "Training complete in 18m 10s\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 5.3778 Acc: 0.2674\n",
      "valid Loss: 6.5086 Acc: 0.1939\n",
      "Training complete in 21m 50s\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "train Loss: 4.1749 Acc: 0.4057\n",
      "valid Loss: 6.1260 Acc: 0.2191\n",
      "Training complete in 25m 29s\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "train Loss: 2.9127 Acc: 0.6086\n",
      "valid Loss: 5.8973 Acc: 0.2419\n",
      "Training complete in 29m 10s\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "train Loss: 1.6257 Acc: 0.8601\n",
      "valid Loss: 5.8347 Acc: 0.2533\n",
      "Training complete in 32m 50s\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "train Loss: 0.6249 Acc: 0.9819\n",
      "valid Loss: 5.8087 Acc: 0.2588\n",
      "Training complete in 36m 28s\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "train Loss: 0.2307 Acc: 0.9964\n",
      "valid Loss: 5.7719 Acc: 0.2639\n",
      "Training complete in 40m 8s\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "train Loss: 0.1584 Acc: 0.9967\n",
      "valid Loss: 5.7569 Acc: 0.2671\n",
      "Training complete in 43m 49s\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "train Loss: 0.1433 Acc: 0.9970\n",
      "valid Loss: 5.7543 Acc: 0.2662\n",
      "Training complete in 47m 29s\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9968\n",
      "valid Loss: 5.7393 Acc: 0.2714\n",
      "Training complete in 51m 6s\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1391 Acc: 0.9969\n",
      "valid Loss: 5.7529 Acc: 0.2671\n",
      "Training complete in 54m 44s\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "train Loss: 0.1384 Acc: 0.9968\n",
      "valid Loss: 5.7427 Acc: 0.2716\n",
      "Training complete in 58m 23s\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "train Loss: 0.1369 Acc: 0.9968\n",
      "valid Loss: 5.7705 Acc: 0.2659\n",
      "Training complete in 62m 3s\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1369 Acc: 0.9967\n",
      "valid Loss: 5.7510 Acc: 0.2698\n",
      "Training complete in 65m 43s\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "train Loss: 0.1358 Acc: 0.9969\n",
      "valid Loss: 5.7663 Acc: 0.2706\n",
      "Training complete in 69m 22s\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "train Loss: 0.1333 Acc: 0.9970\n",
      "valid Loss: 5.7787 Acc: 0.2678\n",
      "Training complete in 73m 1s\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1306 Acc: 0.9972\n",
      "valid Loss: 5.7935 Acc: 0.2689\n",
      "Training complete in 76m 40s\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9968\n",
      "valid Loss: 5.7918 Acc: 0.2685\n",
      "Training complete in 80m 20s\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "train Loss: 0.1301 Acc: 0.9970\n",
      "valid Loss: 5.8055 Acc: 0.2654\n",
      "Training complete in 84m 5s\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1298 Acc: 0.9969\n",
      "valid Loss: 5.8110 Acc: 0.2658\n",
      "Training complete in 87m 47s\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "train Loss: 0.1300 Acc: 0.9968\n",
      "valid Loss: 5.8179 Acc: 0.2687\n",
      "Training complete in 91m 27s\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9970\n",
      "valid Loss: 5.8286 Acc: 0.2685\n",
      "Training complete in 95m 7s\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1277 Acc: 0.9969\n",
      "valid Loss: 5.8289 Acc: 0.2706\n",
      "Training complete in 98m 47s\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "train Loss: 0.1260 Acc: 0.9970\n",
      "valid Loss: 5.8505 Acc: 0.2673\n",
      "Training complete in 102m 25s\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9970\n",
      "valid Loss: 5.8531 Acc: 0.2681\n",
      "Training complete in 106m 3s\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1261 Acc: 0.9969\n",
      "valid Loss: 5.8553 Acc: 0.2678\n",
      "Training complete in 109m 42s\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9971\n",
      "valid Loss: 5.8754 Acc: 0.2663\n",
      "Training complete in 113m 21s\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "train Loss: 0.1228 Acc: 0.9970\n",
      "valid Loss: 5.8784 Acc: 0.2682\n",
      "Training complete in 117m 0s\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1218 Acc: 0.9970\n",
      "valid Loss: 5.8810 Acc: 0.2688\n",
      "Training complete in 120m 39s\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9973\n",
      "valid Loss: 5.8945 Acc: 0.2673\n",
      "Training complete in 124m 18s\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "train Loss: 0.1220 Acc: 0.9970\n",
      "valid Loss: 5.8999 Acc: 0.2679\n",
      "Training complete in 127m 58s\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1205 Acc: 0.9971\n",
      "valid Loss: 5.9127 Acc: 0.2647\n",
      "Training complete in 131m 38s\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "train Loss: 0.1202 Acc: 0.9972\n",
      "valid Loss: 5.9158 Acc: 0.2659\n",
      "Training complete in 135m 17s\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 0.1195 Acc: 0.9970\n",
      "valid Loss: 5.9172 Acc: 0.2660\n",
      "Training complete in 138m 57s\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9973\n",
      "valid Loss: 5.9238 Acc: 0.2667\n",
      "Training complete in 142m 37s\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/tomqin/anaconda3/envs/torch14/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fac3b3f3e2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m---> 11\u001b[0;31m                        num_epochs=NUM_EPOCHS)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-38e452526d74>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# we use optimier to backward loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch14/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch14/lib/python3.6/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch14/lib/python3.6/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model to gpu\n",
    "model = model.cuda()\n",
    "if fp16:\n",
    "    model, optimizer_ft = amp.initialize(model, optimizer_ft, opt_level = \"O1\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "NUM_EPOCHS=60\n",
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 5.9169 Acc: 0.2673\n"
     ]
    }
   ],
   "source": [
    "#valid the model\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in dataloader_valid:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        now_batch_size,c,h,w = inputs.shape\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * now_batch_size\n",
    "\n",
    "        running_corrects += float(torch.sum(preds == labels.data))\n",
    "\n",
    "    epoch_loss = running_loss / len(dataset_valid)\n",
    "    epoch_acc = running_corrects / len(dataset_valid)\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        'valid', epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通拿query的一张图片，在gallery目录里查询符合这个query图片的可能图片（可能存在多张）\n",
    "'''\n",
    "mAP(mean average precision)：反应检索的人在数据库中所有正确的图片排在排序列表前面的程度，能更加全面的衡量ReID算法的性能。\n",
    "如下图，假设该检索行人在gallery中有10张图片，在检索的list中位置（rank）分别为1、2、3、4、5、6、7、8、9，\n",
    "则ap为(1/ 1 + 2 / 2 + 3 / 3 + 4 / 4 + 5 / 5 + 6 / 6 + 7 / 7 + 8 / 8 + 9 / 9) / 10 = 0.90；\n",
    "ap较大时，该行人的检索结果都相对靠前，对所有query的ap取平均值得到mAP\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_network(model, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to test mode\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(index, good_index, junk_index):\n",
    "    ap = 0\n",
    "    cmc = torch.IntTensor(len(index)).zero_()\n",
    "    if good_index.size==0:   # if empty\n",
    "        cmc[0] = -1\n",
    "        return ap,cmc\n",
    "\n",
    "    # remove junk_index\n",
    "    mask = np.in1d(index, junk_index, invert=True)\n",
    "    index = index[mask]\n",
    "\n",
    "    # find good_index index\n",
    "    ngood = len(good_index)\n",
    "    mask = np.in1d(index, good_index)\n",
    "    rows_good = np.argwhere(mask==True)\n",
    "    rows_good = rows_good.flatten()\n",
    "    \n",
    "    cmc[rows_good[0]:] = 1\n",
    "    for i in range(ngood):\n",
    "        d_recall = 1.0/ngood\n",
    "        precision = (i+1)*1.0/(rows_good[i]+1)\n",
    "        if rows_good[i]!=0:\n",
    "            old_precision = i*1.0/rows_good[i]\n",
    "        else:\n",
    "            old_precision=1.0\n",
    "        ap = ap + d_recall*(old_precision + precision)/2\n",
    "\n",
    "    return ap, cmc\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Evaluate\n",
    "def evaluate(qf,ql,qc,gf,gl,gc):\n",
    "    query = qf.view(-1,1)\n",
    "    # print(query.shape)\n",
    "    score = torch.mm(gf,query)\n",
    "    score = score.squeeze(1).cpu()\n",
    "    score = score.numpy()\n",
    "    # predict index\n",
    "    index = np.argsort(score)  #from small to large\n",
    "    index = index[::-1]\n",
    "    # index = index[0:2000]\n",
    "    # good index\n",
    "    query_index = np.argwhere(gl==ql)\n",
    "    camera_index = np.argwhere(gc==qc)\n",
    "\n",
    "    good_index = np.setdiff1d(query_index, camera_index, assume_unique=True)\n",
    "    junk_index1 = np.argwhere(gl==-1)\n",
    "    junk_index2 = np.intersect1d(query_index, camera_index)\n",
    "    junk_index = np.append(junk_index2, junk_index1) #.flatten())\n",
    "    \n",
    "    CMC_tmp = compute_mAP(index, good_index, junk_index)\n",
    "    return CMC_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model,dataloaders):\n",
    "    features = torch.FloatTensor()\n",
    "    count = 0\n",
    "    for data in dataloaders:\n",
    "        img=data.cuda()          \n",
    "        outputs = model(img) \n",
    "        features = torch.cat((features,outputs.data.cpu()), 0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query（查询）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../image_A/query/00000000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../image_A/query/00000001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../image_A/query/00000002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../image_A/query/00000003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../image_A/query/00000004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>../image_A/query/00002895.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>../image_A/query/00002896.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>../image_A/query/00002897.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>../image_A/query/00002898.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>../image_A/query/00002899.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             img_id\n",
       "0     ../image_A/query/00000000.png\n",
       "1     ../image_A/query/00000001.png\n",
       "2     ../image_A/query/00000002.png\n",
       "3     ../image_A/query/00000003.png\n",
       "4     ../image_A/query/00000004.png\n",
       "...                             ...\n",
       "2895  ../image_A/query/00002895.png\n",
       "2896  ../image_A/query/00002896.png\n",
       "2897  ../image_A/query/00002897.png\n",
       "2898  ../image_A/query/00002898.png\n",
       "2899  ../image_A/query/00002899.png\n",
       "\n",
       "[2900 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#query\n",
    "query_list=glob.glob(r'../image_A/query/*.png')\n",
    "query_name_list=[]\n",
    "for file_path   in query_list:\n",
    "    file_name=file_path\n",
    "    query_name_list.append(file_name)\n",
    "\n",
    "query_df=pd.DataFrame(data={'img_id':query_name_list})\n",
    "query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_query = ReIDDatasetTest(df=query_df, transforms=transforms_train)\n",
    "dataloader_query = DataLoader(dataset_query, batch_size=VAL_BATCH_SIZE, num_workers=2, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "for img in dataloader_query:\n",
    "    print(img.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gallery（待搜索图库）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../image_A/gallery/00000000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../image_A/gallery/00000006.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../image_A/gallery/00000009.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../image_A/gallery/00000012.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../image_A/gallery/00000016.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40461</th>\n",
       "      <td>../image_A/gallery/00143698.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40462</th>\n",
       "      <td>../image_A/gallery/00143707.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40463</th>\n",
       "      <td>../image_A/gallery/00143708.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40464</th>\n",
       "      <td>../image_A/gallery/00143710.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40465</th>\n",
       "      <td>../image_A/gallery/00143711.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40466 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                img_id\n",
       "0      ../image_A/gallery/00000000.png\n",
       "1      ../image_A/gallery/00000006.png\n",
       "2      ../image_A/gallery/00000009.png\n",
       "3      ../image_A/gallery/00000012.png\n",
       "4      ../image_A/gallery/00000016.png\n",
       "...                                ...\n",
       "40461  ../image_A/gallery/00143698.png\n",
       "40462  ../image_A/gallery/00143707.png\n",
       "40463  ../image_A/gallery/00143708.png\n",
       "40464  ../image_A/gallery/00143710.png\n",
       "40465  ../image_A/gallery/00143711.png\n",
       "\n",
       "[40466 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gallery\n",
    "gallery_list=glob.glob(r'../image_A/gallery/*.png')\n",
    "gallery_name_list=[]\n",
    "for file_path   in gallery_list:\n",
    "    #     file_name=file_path.split('/')[-1]\n",
    "    file_name=file_path\n",
    "    gallery_name_list.append(file_name)\n",
    "#     break\n",
    "# print((query_list))\n",
    "gallery_df=pd.DataFrame(data={'img_id':gallery_name_list})\n",
    "gallery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gallery字典，用于根据索引反向获得对应的图片id\n",
    "gallery_dict={}\n",
    "for i,file in enumerate(gallery_df.img_id.values):\n",
    "    gallery_dict[i]=file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gallery = ReIDDatasetTest(df=gallery_df, transforms=transforms_train)\n",
    "dataloader_gallery = DataLoader(dataset_gallery, batch_size=VAL_BATCH_SIZE, num_workers=2, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000.png'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽取query特征和gallery特征，准备计算距离做排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature\n",
    "with torch.no_grad():\n",
    "    query_feature = extract_feature(model,dataloader_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2900, 19658])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feature.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature\n",
    "with torch.no_grad():\n",
    "    gallery_feature = extract_feature(model,dataloader_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40466, 19658])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_feature.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfind rank1 positional information\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = query_feature.size(0), gallery_feature.size(0)\n",
    "distmat = torch.pow(query_feature, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "          torch.pow(gallery_feature, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "distmat.addmm_(1, -2, query_feature, gallery_feature.t())\n",
    "distmat = distmat.numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序取前200\n",
    "indices = np.argsort(distmat,1)\n",
    "indices_200 = indices[:,:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2900, 40466), (2900, 40466))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmat.shape,indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([52697.695, 78874.87 , 57114.316, ..., 56367.2  , 49260.613,\n",
       "        72397.86 ], dtype=float32),\n",
       " array([32001, 37225, 16589, ..., 39009, 22941, 15142]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmat[0],indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2900, 200)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_200.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成用来导出json的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_name_list\n",
    "new_dict={}\n",
    "for j,a in enumerate(indices_200.tolist()):\n",
    "    line_arr=[]\n",
    "    counter+=1\n",
    "    for i in a:\n",
    "        line_arr.append(gallery_dict[i])\n",
    "    key=query_name_list[j].split('/')[-1]\n",
    "\n",
    "    new_dict[key]=list(line_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_name_list\n",
    "# new_dict={}\n",
    "# with open(\"submission_0826.json\",\"w\",encoding='utf-8') as fout:\n",
    "#     fout.write('{')\n",
    "#     for j,a in enumerate(indices_200.tolist()):\n",
    "#         line_arr=[]\n",
    "#         counter+=1\n",
    "#         str_arr=''\n",
    "#         for i in a:\n",
    "#             line_arr.append(gallery_dict[i])\n",
    "#             str_arr+='\\\"{}\\\",'.format(gallery_dict[i])\n",
    "#         key=query_name_list[j].split('/')[-1]\n",
    "# #         line_str='\\\"{}\\\":[{}]\\n'.format(key,str_arr[:-1])\n",
    "#         line_str='\\\"{}\\\":[{}]'.format(key,str_arr[:-1])\n",
    "\n",
    "#         fout.write(line_str+',')\n",
    "#     fout.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载入文件完成...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"submission_0826.json\",\"w\") as f:\n",
    "    json.dump(new_dict,f)\n",
    "    print(\"加载入文件完成...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"00000000.png\": [\"00113784.png\", \"00132168.png\", \"00058828.png\", \"00111189.png\", \"00136251.png\", \"00049582.png\", \"00043037.png\", \"00124806.png\", \"00120209.png\", \"00106560.png\", \"00002368.png\", \"00098689.png\", \"00128112.png\", \"00059088.png\", \"00102430.png\", \"00128367.png\", \"00028445.png\", \"00128727.png\", \"00046388.png\", \"00102983.png\", \"00062888.png\", \"00114940.png\", \"00106806.png\", \"00121973.png\", \"00044722.png\", \"00041101.png\", \"00012701.png\", \"00055319.png\", \"00021437.png\", \"00082180.png\", \"00083046.png\", \"00102891.png\", \"00002120.png\", \"00093492.png\", \"00089232.png\", \"00051046.png\", \"00045632.png\", \"00125816.png\", \"00032149.png\", \"00110083.png\", \"00071599.png\", \"00019856.png\", \"00041288.png\", \"00100146.png\", \"00021927.png\", \"00081096.png\", \"00041469.png\", \"00019634.png\", \"00125209.png\", \"00028638.png\", \"00116918.png\", \"00041662.png\", \"00045368.png\", \"00021149.png\", \"00075311.png\", \"00129853.png\", \"00039597.png\", \"00010708.png\", \"00059308.png\", \"00009919.png\", \"00119033.png\", \"00139824.png\", \"00025088.png\", \"00014017.png\", \"00042163.png\", \"00136369.png\", \"00006706.png\", \"00129756.png\", \"00083226.png\", \"00023757.png\", \"00024823.png\", \"00086475.png\", \"00069199.png\", \"00067611.png\", \"00010744.png\", \"00008635.png\", \"00099823.png\", \"00077809.png\", \"00013289.png\", \"00101425.png\", \"00124458.png\", \"00022502.png\", \"00114512.png\", \"00062863.png\", \"00026920.png\", \"00108330.png\", \"00017844.png\", \"00135209.png\", \"00125648.png\", \"00049804.png\", \"00070536.png\", \"00101060.png\", \"00048081.png\", \"00140308.png\", \"00067916.png\", \"00083015.png\", \"00032852.png\", \"00084279.png\", \"00128119.png\", \"00111988.png\", \"00094606.png\", \"00033336.png\", \"00009441.png\", \"00142562.png\", \"00063937.png\", \"00037353.png\", \"00024476.png\", \"00011720.png\", \"00112179.png\", \"00125815.png\", \"00130365.png\", \"00039901.png\", \"00025109.png\", \"00136775.png\", \"00136194.png\", \"00037422.png\", \"00026154.png\", \"00110315.png\", \"00055145.png\", \"00074412.png\", \"00078708.png\", \"00085589.png\", \"00031243.png\", \"00059211.png\", \"00024915.png\", \"00056753.png\", \"00128179.png\", \"00055054.png\", \"00139138.png\", \"00012931.png\", \"00134122.png\", \"00111084.png\", \"00108361.png\", \"00115766.png\", \"00126086.png\", \"00106957.png\", \"00013102.png\", \"00013502.png\", \"00140752.png\", \"00055269.png\", \"00058316.png\", \"00068065.png\", \"00037705.png\", \"00067390.png\", \"00049939.png\", \"00061445.png\", \"00074905.png\", \"00116928.png\", \"00033826.png\", \"00082684.png\", \"00064490.png\", \"00062733.png\", \"00059906.png\", \"00115931.png\", \"00097800.png\", \"00119517.png\", \"00021770.png\", \"00069128.png\", \"00012898.png\", \"00014356.png\", \"00030146.png\", \"00022637.png\", \"00066853.png\", \"00068217.png\", \"00044899.png\", \"00066385.png\", \"00054980.png\", \"00010809.png\", \"00031668.png\", \"00007294.png\", \"00113135.png\", \"00110543.png\", \"00010433.png\", \"00000860.png\", \"00040908.png\", \"00126192.png\", \"00143287.png\", \"00070145.png\", \"00062988.png\", \"00060711.png\", \"00059839.png\", \"00104808.png\", \"00104176.png\", \"00062917.png\", \"00127274.png\", \"00091542.png\", \"00069954.png\", \"00025416.png\", \"00058625.png\", \"00041728.png\", \"00102063.png\", \"00020616.png\", \"00043891.png\", \"00015198.png\", \"00082194.png\", \"00074796.png\", \"00053886.png\", \"00118019.png\", \"00089176.png\", \"00055544.png\"], \"00000001.png\": [\"00072943.png\", \"00063259.png\", \"00122334.png\", \"00096556.png\", \"00081918.png\", \"00013324.png\", \"00009801.png\", \"00029384.png\", \"00006566.png\", \"00082715.png\", \"00055083.png\", \"00127520.png\", \"00078754.png\", \"00037287.png\", \"00086494.png\", \"00142951.png\", \"00117450.png\", \"00100378.png\", \"00141940.png\", \"00049916.png\", \"00119033.png\", \"00128727.png\", \"00042372.png\", \"00098443.png\", \"00042163.png\", \"00019388.png\", \"00035834.png\", \"00073654.png\", \"00020093.png\", \"00091605.png\", \"00138759.png\", \"00089352.png\", \"00035315.png\", \"00090947.png\", \"00100187.png\", \"00106806.png\", \"00009757.png\", \"00055764.png\", \"00117774.png\", \"00127085.png\", \"00075965.png\", \"00092105.png\", \"00055042.png\", \"00038298.png\", \"00030027.png\", \"00139138.png\", \"00108473.png\", \"00101311.png\", \"00062308.png\", \"00041678.png\", \"00066696.png\", \"00110273.png\", \"00059037.png\", \"00013056.png\", \"00121933.png\", \"00040512.png\", \"00039382.png\", \"00058205.png\", \"00107192.png\", \"00055878.png\", \"00057835.png\", \"00051737.png\", \"00071269.png\", \"00113532.png\", \"00062790.png\", \"00059618.png\", \"00013158.png\", \"00116681.png\", \"00083686.png\", \"00063335.png\", \"00007462.png\", \"00049406.png\", \"00032229.png\", \"00054722.png\", \"00070761.png\", \"00048669.png\", \"00092999.png\", \"00142537.png\", \"00133812.png\", \"00026913.png\", \"00142707.png\", \"00108945.png\", \"00040176.png\", \"00054450.png\", \"00014692.png\", \"00118155.png\", \"00088258.png\", \"00025527.png\", \"00135667.png\", \"00000143.png\", \"00082194.png\", \"00020730.png\", \"00097533.png\", \"00102394.png\", \"00054011.png\", \"00074211.png\", \"00059088.png\", \"00087994.png\", \"00119369.png\", \"00142803.png\", \"00119672.png\", \"00013614.png\", \"00055493.png\", \"00116701.png\", \"00007109.png\", \"00015487.png\", \"00010334.png\", \"00031698.png\", \"00063307.png\", \"00101745.png\", \"00044426.png\", \"00044352.png\", \"00079317.png\", \"00035770.png\", \"00048967.png\", \"00131702.png\", \"00072032.png\", \"00072528.png\", \"00018621.png\", \"00134087.png\", \"00036941.png\", \"00060532.png\", \"00070224.png\", \"00098477.png\", \"00039148.png\", \"00092937.png\", \"00032647.png\", \"00112775.png\", \"00027984.png\", \"00022158.png\", \"00069315.png\", \"00134122.png\", \"00037347.png\", \"00042749.png\", \"00108078.png\", \"00008814.png\", \"00056461.png\", \"00102188.png\", \"00134010.png\", \"00115989.png\", \"00100037.png\", \"00026459.png\", \"00065347.png\", \"00134769.png\", \"00103214.png\", \"00044873.png\", \"00049939.png\", \"00019996.png\", \"00055405.png\", \"00016849.png\", \"00014957.png\", \"00128678.png\", \"00054062.png\", \"00070421.png\", \"00099749.png\", \"00137298.png\", \"00025753.png\", \"00092550.png\", \"00130376.png\", \"00133186.png\", \"00032542.png\", \"00089545.png\", \"00111414.png\", \"00064986.png\", \"00107534.png\", \"00071969.png\", \"00086927.png\", \"00047566.png\", \"00082806.png\", \"00081773.png\", \"00073154.png\", \"00078104.png\", \"00129504.pn\n"
     ]
    }
   ],
   "source": [
    "#检查生成的文件\n",
    "with open(\"submission_0826.json\",\"r\") as fin:\n",
    "    for line in fin:\n",
    "        print(line[:6000])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')\n",
    "#lb 0.235"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
